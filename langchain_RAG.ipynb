{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai langchain-chroma bs4 Flask \n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install unstructured\n",
    "!pip install chromadb\n",
    "!pip install tiktoken\n",
    "!pip install tabulate\n",
    "!pip install Flask\n",
    "# Python要3.11以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#導出環境\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#安裝環境\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "apikey = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=256,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立本機知識庫QA機器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI,VectorDBQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# 載入資料夾中所有TXT檔案\n",
    "loader = DirectoryLoader('D:\\Langchain_RAG_Docker\\RAG_Data', glob='**/*.txt')\n",
    "\n",
    "# 將資料轉成document物佚，每個檔案會為作為一個document\n",
    "documents = loader.load()\n",
    "\n",
    "# 初始化載入器\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "\n",
    "# 切割加载的 document\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 初始化 openai 的 embeddings 物件\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 將 document 透過 openai 的 embeddings 物件計算 embedding向量資料暫時存入 Chroma 向量資料庫用於後續的搜尋\n",
    "docsearch = Chroma.from_documents(split_docs, embeddings)\n",
    "\n",
    "# 建立回答物件\n",
    "qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch, return_source_documents=True)\n",
    "\n",
    "# 進行回答\n",
    "result = qa({\"query\": \"工專時期第3任校長是誰\"})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 網頁問答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAi語言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI,VectorDBQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory \n",
    "from langchain.chains import  ConversationalRetrievalChain\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=256,\n",
    "    )                                                  \n",
    "# 載入資料夾中所有TXT檔案\n",
    "loader = DirectoryLoader('D:\\Langchain_RAG_Docker\\RAG_Data', glob='**/*.txt')\n",
    "# 將資料轉成document物佚，每個檔案會為作為一個document\n",
    "documents = loader.load()\n",
    "# 初始化載入器\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "# 切割加载的 document\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "# 初始化 openai 的 embeddings 物件\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# 將 document 透過 openai 的 embeddings 物件計算 embedding向量資料暫時存入 Chroma 向量資料庫用於後續的搜尋\n",
    "docsearch = Chroma.from_documents(split_docs, embeddings)\n",
    "# 建立回答物件\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.1)\n",
    "qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch, return_source_documents=True)\n",
    "\n",
    "\n",
    "retriever = docsearch.as_retriever(search_type = \"similarity\",search_kwargs={\"k\":5})\n",
    "#測試2\n",
    "memory = ConversationBufferMemory (llm=llm , output_key='answer', memory_key='chat_history',return_messages=True)\n",
    "converstation = ConversationalRetrievalChain.from_llm(llm=llm,retriever=retriever, memory=memory)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "#@app.route('/ask', methods=['POST'])\n",
    "@app.route('/ask', methods=['GET'])\n",
    "def ask_question():\n",
    "    #question = request.form['question']\n",
    "    question = request.args.get('question')\n",
    "    # result = qa({\"query\": question})\n",
    "    result = converstation({\"question\":question})\n",
    "    # return result['result']\n",
    "    return result['answer']\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
